{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code contains pre-processing steps done on [CelebA dataset](https://www.kaggle.com/jessicali9530/celeba-dataset) from Kaggle to prepare for multi-class facial attribute classification model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Boiler Plate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T21:16:15.337275Z",
     "start_time": "2019-01-24T21:16:12.646114Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/matplotlib/font_manager.py:278: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  'Matplotlib is building the font cache using fc-list. '\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T21:16:18.042812Z",
     "start_time": "2019-01-24T21:16:15.342223Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50f8d4cd1e78422087ee87dbc82f5868",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import imutils\n",
    "import glob\n",
    "import cv2\n",
    "import shutil\n",
    "from tqdm import tqdm_notebook\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_columns', 500)\n",
    "tqdm_notebook().pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Downloading databse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We are going to download [CelebFaces Attributes(CelebA) dataset](https://www.kaggle.com/jessicali9530/celeba-dataset) from Kaggle. This dataset is excellent for training and testing models for face detection, particularly for recognizing facial attributes such as finding people with brown hair, are smiling, or wearing glasses. Images cover large pose variations, background clutter, diverse people, supported by a large number of images and rich annotations. This data was originally collected by researchers at MMLAB, The Chinese University of Hong Kong (specific reference in Acknowledgment section).\n",
    "\n",
    "**Content**\n",
    "\n",
    "- 202,599 number of face images of various celebrities\n",
    "- 10,177 unique identities, but names of identities are not given\n",
    "- 40 binary attribute annotations per image\n",
    "- 5 landmark locations\n",
    "\n",
    "We are going to use kaggle-cli to download data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T05:04:05.729302Z",
     "start_time": "2019-01-24T05:04:05.700665Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/ubuntu/.kaggle/kaggle.json'\n",
      "Downloading celeba-dataset.zip to /home/ubuntu/code/Deep_learning_explorations/7_Facial_attributes_fastai_opencv\n",
      " 98%|█████████████████████████████████████▎| 1.31G/1.33G [00:13<00:00, 98.5MB/s]\n",
      "100%|███████████████████████████████████████| 1.33G/1.33G [00:13<00:00, 103MB/s]\n"
     ]
    }
   ],
   "source": [
    "## !kaggle datasets download -d jessicali9530/celeba-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting frontal face from images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CelebA dataset contains images of faces which are taken from the side and with different orientation and zoom angle. The first step of preprocessing is you select images which in which front face is visible and isolate that part of the image alone for our model training of facial attributes. We are going to use OpenCV Haar Cascades to find the location of the face in the image and crop to only keep the facial parts of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T21:16:18.291354Z",
     "start_time": "2019-01-24T21:16:18.072519Z"
    }
   },
   "outputs": [],
   "source": [
    "## Loading Haar Cascade\n",
    "## Taken from https://github.com/opencv/opencv/tree/master/data/haarcascades\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T21:16:19.110303Z",
     "start_time": "2019-01-24T21:16:19.067567Z"
    }
   },
   "outputs": [],
   "source": [
    "def face_extractor(origin, destination, fc):\n",
    "    ## Importing image using open cv\n",
    "    img = cv2.imread(origin,1)\n",
    "\n",
    "    ## Resizing to constant width\n",
    "    img = imutils.resize(img, width=200)\n",
    "    \n",
    "    ## Finding actual size of image\n",
    "    H,W,_ = img.shape\n",
    "    \n",
    "    ## Converting BGR to RGB\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    ## Detecting faces on the image\n",
    "    face_coord = fc.detectMultiScale(gray,1.2,10,minSize=(50,50))\n",
    "    \n",
    "    ## If only one face is foung\n",
    "    if len(face_coord) == 1:\n",
    "        X, Y, w, h = face_coord[0]\n",
    "    \n",
    "    ## If no face found --> SKIP\n",
    "    elif len(face_coord)==0:\n",
    "        return None\n",
    "    \n",
    "    ## If multiple faces are found take the one with largest area\n",
    "    else:\n",
    "        max_val = 0\n",
    "        max_idx = 0\n",
    "        for idx in range(len(face_coord)):\n",
    "            _, _, w_i, h_i = face_coord[idx]\n",
    "            if w_i*h_i > max_val:\n",
    "                max_idx = idx\n",
    "                max_val = w_i*h_i\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "            X, Y, w, h = face_coord[max_idx]\n",
    "    \n",
    "    ## Crop and export the image\n",
    "    img_cp = img[\n",
    "            max(0,Y - int(0.35*h)): min(Y + int(1.35*h), H),\n",
    "            max(0,X - int(w*0.35)): min(X + int(1.35*w), W)\n",
    "        ].copy()\n",
    "    \n",
    "    cv2.imwrite(destination, img_cp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T21:16:26.977196Z",
     "start_time": "2019-01-24T21:16:23.864329Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202599\n"
     ]
    }
   ],
   "source": [
    "## Defining destination path\n",
    "path = 'data/faces/'\n",
    "\n",
    "## Finding all the images in the folder\n",
    "item_list = glob.glob('data/img_align_celeba/img_align_celeba/*.jpg')\n",
    "print(len(item_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T05:10:20.445764Z",
     "start_time": "2019-01-24T05:09:00.264576Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63752bdcc74a4371b92a5ab576ac1ae8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=202599), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Will run for about 45 min\n",
    "for org in tqdm_notebook(item_list):\n",
    "    face_extractor(origin = org, destination = path+org.split('/')[-1], fc=face_cascade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebe23970babb4495ab9a09c38e1f39ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=202599), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Findign all the images and separating in training and validation\n",
    "item_list = glob.glob(path+'*.jpg')\n",
    "\n",
    "for idx in tqdm_notebook(range(1,202600)):\n",
    "    if idx <= 182637:\n",
    "        destination = path+'training/'\n",
    "    else:\n",
    "        destination = path+'validation/'\n",
    "    try:\n",
    "        shutil.move(\n",
    "            path+str(idx).zfill(6)+'.jpg', \n",
    "            destination+str(idx).zfill(6)+'.jpg'\n",
    "        )\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2da96089845f462ebaca990f278a5ad4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=202599), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Combining all label attributes\n",
    "label_df = pd.read_csv('data/list_attr_celeba.csv')\n",
    "column_list = pd.Series(list(label_df.columns)[1:])\n",
    "\n",
    "def label_generator(row):\n",
    "    return(' '.join(column_list[[True if i==1 else False for i in row[column_list]]]))\n",
    "\n",
    "label_df['label'] = label_df.progress_apply(lambda x: label_generator(x), axis=1)\n",
    "label_df = label_df.loc[:,['image_id','label']]\n",
    "label_df.to_csv('data/labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Attachhing label to correct file names\n",
    "item_list = glob.glob('data/faces/*/*.jpg')\n",
    "item_df = pd.DataFrame({'image_name':pd.Series(item_list).apply(lambda x: '/'.join(x.split('/')[-2:]))})\n",
    "item_df['image_id'] = item_df.image_name.apply(lambda x: x.split('/')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating final label set\n",
    "label_df = pd.read_csv('data/labels.csv')\n",
    "label_df = label_df.merge(item_df, on='image_id', how='inner')\n",
    "label_df.rename(columns={'label':'tags'}, inplace=True)\n",
    "label_df.loc[:,['image_name','tags']].to_csv('data/faces/labels.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>image_id</th>\n",
       "      <th>tags</th>\n",
       "      <th>image_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>000001.jpg</td>\n",
       "      <td>Arched_Eyebrows Attractive Brown_Hair Heavy_Ma...</td>\n",
       "      <td>training/000001.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>000002.jpg</td>\n",
       "      <td>Bags_Under_Eyes Big_Nose Brown_Hair High_Cheek...</td>\n",
       "      <td>training/000002.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>000005.jpg</td>\n",
       "      <td>Arched_Eyebrows Attractive Big_Lips Heavy_Make...</td>\n",
       "      <td>training/000005.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>000006.jpg</td>\n",
       "      <td>Arched_Eyebrows Attractive Big_Lips Brown_Hair...</td>\n",
       "      <td>training/000006.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>000007.jpg</td>\n",
       "      <td>5_o_Clock_Shadow Attractive Bags_Under_Eyes Bi...</td>\n",
       "      <td>training/000007.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    image_id                                               tags  \\\n",
       "0           0  000001.jpg  Arched_Eyebrows Attractive Brown_Hair Heavy_Ma...   \n",
       "1           1  000002.jpg  Bags_Under_Eyes Big_Nose Brown_Hair High_Cheek...   \n",
       "2           4  000005.jpg  Arched_Eyebrows Attractive Big_Lips Heavy_Make...   \n",
       "3           5  000006.jpg  Arched_Eyebrows Attractive Big_Lips Brown_Hair...   \n",
       "4           6  000007.jpg  5_o_Clock_Shadow Attractive Bags_Under_Eyes Bi...   \n",
       "\n",
       "            image_name  \n",
       "0  training/000001.jpg  \n",
       "1  training/000002.jpg  \n",
       "2  training/000005.jpg  \n",
       "3  training/000006.jpg  \n",
       "4  training/000007.jpg  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
